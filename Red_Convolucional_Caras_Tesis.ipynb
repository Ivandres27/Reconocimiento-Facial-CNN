{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Verifica GPU\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cargar datos\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "mat_contents = scipy.io.loadmat(os.path.join(\"/home/ivana/ml_projects/allFaces.mat\"))\n",
    "faces = mat_contents['faces']\n",
    "m = int(mat_contents['m'])\n",
    "n = int(mat_contents['n'])\n",
    "nfaces = np.ndarray.flatten(mat_contents['nfaces'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create etiquetas para cada cara\n",
    "labels = np.zeros(faces.shape[1])\n",
    "for i in range(len(nfaces)):\n",
    "  labels[np.sum(nfaces[:(i)]):np.sum(nfaces[:(i+1)])] = i+1\n",
    "\n",
    "# Agregarlas etiquetas al arreglo faces\n",
    "faces = np.concatenate((labels.reshape((1, faces.shape[1])), faces), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "#Ordenar el areglo en vectores columna\n",
    "faces_aux = faces.T\n",
    "X = faces_aux[:,1:]\n",
    "y = faces_aux[:,0]\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Imprimir las formas de los conjuntos de entrenamiento y prueba\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calcular la cantidad de imágenes de cada dígito en X_train y X_test\n",
    "num_imagenes_digito_train = {int(digito): int(np.sum(y_train == digito)) for digito in np.unique(y_train)}\n",
    "num_imagenes_digito_test = {int(digito): int(np.sum(y_test == digito)) for digito in np.unique(y_test)}\n",
    "\n",
    "# Imprimir la cantidad de imágenes de cada dígito en X_train y X_test\n",
    "print(\"Número de imágenes de cada dígito en X_train:\")\n",
    "print(dict(sorted(num_imagenes_digito_train.items())))\n",
    "\n",
    "print(\"\\nNúmero de imágenes de cada dígito en X_test:\")\n",
    "print(dict(sorted(num_imagenes_digito_test.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir y_train a un DataFrame de pandas\n",
    "df_train = pd.DataFrame({'label': y_train})\n",
    "\n",
    "# Crear una cuadrícula de gráficos con una gráfica para cada dígito\n",
    "g = sns.FacetGrid(df_train, height=7, aspect=5)\n",
    "g.map(sns.countplot, 'label', palette=\"icefire\",order=sorted(df_train['label'].unique()))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Obtener el recuento de valores únicos en y_train\n",
    "print(df_train['label'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagen ejemplo\n",
    "img = X_train[9,:]\n",
    "img = img.reshape((m,n)).T\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.title(\"Ejemplo\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "X_train = X_train.reshape(-1,n,m,1)\n",
    "X_test = X_test.reshape(-1,n,m,1)\n",
    "\n",
    "#Tamaños\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Restar 1 a las etiquetas para que empiecen desde 0\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "# Aplicar one-hot encoding especificando num_classes\n",
    "y_train = to_categorical(y_train, num_classes=38)\n",
    "y_test = to_categorical(y_test, num_classes=38)\n",
    "\n",
    "# Verificar las dimensiones\n",
    "num_clases = y_test.shape[1]\n",
    "print(\"Forma de y_train después de one-hot:\", y_train.shape)\n",
    "print(\"Forma de y_test después de one-hot:\", y_test.shape)\n",
    "print(\"Número de clases:\", num_clases)\n",
    "\n",
    "# Verificar que tenemos todas las clases\n",
    "print(\"Número único de clases en y_train:\", len(np.unique(np.argmax(y_train, axis=1))))\n",
    "print(\"Número único de clases en y_test:\", len(np.unique(np.argmax(y_test, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "#\n",
    "model.add(Conv2D(filters = 8, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (n,m,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "#\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(38, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30  # for better result increase the epochs\n",
    "batch_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center = False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False,  # divide each input by its std\n",
    "        zca_whitening = False,  # dimesion reduction\n",
    "        rotation_range = 0,  # randomly rotate images in the range 5 degrees\n",
    "        zoom_range = 0, # Randomly zoom image 10%\n",
    "        width_shift_range = 0,  # randomly shift images horizontally 10%\n",
    "        height_shift_range = 0,  # randomly shift images vertically 10%\n",
    "        horizontal_flip = False,  # randomly flip images\n",
    "        vertical_flip = False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(datagen.flow(X_train,y_train,batch_size=batch_size), validation_data=(X_test,y_test), epochs=epochs)\n",
    "\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "plt.plot(history.history['val_loss'], color='g', label=\"validation loss\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNúmero de imágenes de cada dígito en X_test:\")\n",
    "print(num_imagenes_digito_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración\n",
    "num_classes = 38\n",
    "class_names = [f\"Persona {i+1:02d}\" for i in range(num_classes)]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ANÁLISIS DEL MODELO - YALE FACES (38 PERSONAS)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Modelo: {model.name}\")\n",
    "print(f\"Input shape del modelo: {model.input_shape}\")\n",
    "print(f\"Shape de X_test: {X_test.shape}\")\n",
    "print(f\"Shape de y_test: {y_test.shape}\")\n",
    "\n",
    "# Hacer predicciones DIRECTAMENTE (sin preprocesamiento)\n",
    "print(\"\\nHaciendo predicciones...\")\n",
    "predictions = model.predict(X_test, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test\n",
    "\n",
    "# Accuracy general\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✅ ACCURACY GENERAL: {accuracy*100:.2f}%\")\n",
    "print(f\"   Predicciones correctas: {np.sum(predicted_classes == true_classes)}/{len(y_test)}\")\n",
    "print(f\"   Predicciones incorrectas: {np.sum(predicted_classes != true_classes)}/{len(y_test)}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# ===== ACCURACY POR PERSONA =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ACCURACY POR PERSONA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "person_accuracy = []\n",
    "for person_id in range(num_classes):\n",
    "    mask = true_classes == person_id\n",
    "    if np.sum(mask) > 0:\n",
    "        person_acc = np.mean(predicted_classes[mask] == true_classes[mask])\n",
    "        person_accuracy.append((person_id, person_acc, np.sum(mask)))\n",
    "\n",
    "# Ordenar por accuracy\n",
    "person_accuracy.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n🏆 TOP 10 - Mejor reconocimiento:\")\n",
    "for i, (person_id, acc, count) in enumerate(person_accuracy[:10], 1):\n",
    "    print(f\"  {i:2d}. {class_names[person_id]}: {acc*100:5.1f}% ({count} imágenes)\")\n",
    "\n",
    "print(\"\\n⚠️  BOTTOM 10 - Necesitan mejorar:\")\n",
    "for i, (person_id, acc, count) in enumerate(person_accuracy[-10:], 1):\n",
    "    print(f\"  {i:2d}. {class_names[person_id]}: {acc*100:5.1f}% ({count} imágenes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar errores\n",
    "errors = predicted_classes != true_classes\n",
    "error_indices = np.where(errors)[0]\n",
    "\n",
    "if len(error_indices) > 0:\n",
    "    from collections import Counter\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANÁLISIS DE ERRORES\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nTotal de errores: {len(error_indices)} de {len(X_test)} ({len(error_indices)/len(X_test)*100:.2f}%)\")\n",
    "    \n",
    "    # Confusiones más frecuentes\n",
    "    confusions = [(true_classes[i], predicted_classes[i]) for i in error_indices]\n",
    "    most_common = Counter(confusions).most_common(10)\n",
    "    \n",
    "    print(\"\\n10 confusiones más frecuentes:\")\n",
    "    for i, ((true_id, pred_id), count) in enumerate(most_common, 1):\n",
    "        print(f\"  {i:2d}. {class_names[true_id]} → {class_names[pred_id]} : {count} veces\")\n",
    "    \n",
    "    # Visualizar ejemplos de errores\n",
    "    print(\"\\nVisualizando ejemplos de errores...\")\n",
    "    n_errors_show = min(10, len(error_indices))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(18, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, idx in enumerate(error_indices[:n_errors_show]):\n",
    "        image = X_test[idx]\n",
    "        true_id = true_classes[idx]\n",
    "        pred_id = predicted_classes[idx]\n",
    "        confidence = predictions[idx][pred_id]\n",
    "        \n",
    "        if len(image.shape) == 3 and image.shape[2] == 1:\n",
    "            axes[i].imshow(image.squeeze(), cmap='gray')\n",
    "        else:\n",
    "            axes[i].imshow(image, cmap='gray')\n",
    "        \n",
    "        title = f\"Real: {class_names[true_id]}\\nPred: {class_names[pred_id]}\\nConf: {confidence*100:.0f}%\"\n",
    "        axes[i].set_title(title, color='red', fontsize=9, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Ejemplos de Errores de Clasificación', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n🎉 ¡Modelo perfecto! No hay errores en el conjunto de prueba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sns\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(30, 30))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Blues\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes tu generador configurado y entrenaste el modelo\n",
    "# Por ejemplo: después de model.fit(...)\n",
    "\n",
    "# 1. Crear y guardar class_names (si usas nombres generados)\n",
    "class_names = [f\"persona_{i+1}\" for i in range(38)]  # O usa train_generator.class_indices si viene de carpetas\n",
    "np.save('nombres_clases.npy', class_names)\n",
    "print(\"Nombres de clases guardados como 'nombres_clases.npy'\")\n",
    "\n",
    "# 2. Guardar el modelo\n",
    "model.save('modelo_rostros.h5')\n",
    "print(\"Modelo guardado como 'modelo_rostros.h5'\")\n",
    "\n",
    "print(\"¡Todo guardado exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "# Cargar modelo\n",
    "model = load_model('modelo_rostros.h5')\n",
    "\n",
    "# Cargar nombres\n",
    "class_names = np.load('nombres_clases.npy', allow_pickle=True).tolist()\n",
    "\n",
    "print(\"Modelo y nombres cargados.\")\n",
    "# Ahora úsalos en predicciones: nombre = class_names[clase_predicha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# === REMAPEAR ETIQUETAS A 0,1,2,...,37 ===\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Convierte cualquier etiqueta a 0–37\n",
    "\n",
    "# Verificar que ahora sí están en 0–37\n",
    "print(\"Etiquetas originales únicas:\", np.unique(y))\n",
    "print(\"Etiquetas codificadas únicas (0 a 37):\", np.unique(y_encoded))\n",
    "print(f\"Número de clases: {len(np.unique(y_encoded))}\")  # Debe ser 38\n",
    "\n",
    "# === Dividir con etiquetas codificadas ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Convertir a int\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# === GUARDAR EL MAPEO PARA USARLO DESPUÉS ===\n",
    "np.save('label_encoder_classes.npy', label_encoder.classes_)  # IDs originales\n",
    "class_names = [f\"persona_{i+1}\" for i in range(38)]\n",
    "np.save('nombres_clases.npy', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ================= CARGAR MODELO Y CLASES =================\n",
    "MODEL_PATH = 'modelo_rostros.h5'\n",
    "CLASES_PATH = 'nombres_clases.npy'\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "class_names = np.load(CLASES_PATH, allow_pickle=True).tolist()\n",
    "\n",
    "print(f\"Modelo y clases cargados. Total clases: {len(class_names)}\")\n",
    "\n",
    "# ================= TUS DATOS (ya los tienes) =================\n",
    "# X_train, X_test, y_train, y_test → ya definidos\n",
    "# Suponiendo que las imágenes están aplanadas: (n_samples, n_pixels)\n",
    "\n",
    "IMG_HEIGHT = n # Cambia si usaste otro\n",
    "IMG_WIDTH = m\n",
    "N_PIXELS = IMG_HEIGHT * IMG_WIDTH  # Debe coincidir con X_train.shape[1]\n",
    "\n",
    "\n",
    "# ================= FUNCIÓN: Predecir un batch de imágenes =================\n",
    "def predecir_batch(X_batch, model, class_names):\n",
    "    # Redimensionar: (n_samples, n_pixels) → (n_samples, 64, 64, 1)\n",
    "    X_batch = X_batch.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    X_batch = X_batch / 255.0  # Normalización\n",
    "\n",
    "    # Predicción\n",
    "    predicciones = model.predict(X_batch, verbose=0)\n",
    "    clases_predichas = np.argmax(predicciones, axis=1)\n",
    "    confianzas = np.max(predicciones, axis=1)\n",
    "\n",
    "    return clases_predichas, confianzas, predicciones\n",
    "\n",
    "# ================= EJEMPLO: Predecir en X_test =================\n",
    "print(\"\\nHaciendo predicciones en X_test...\")\n",
    "\n",
    "y_pred, confianzas, probs = predecir_batch(X_test, model, class_names)\n",
    "\n",
    "# ================= MOSTRAR ALGUNOS RESULTADOS =================\n",
    "print(\"\\nPrimeras 10 predicciones en X_test:\")\n",
    "for i in range(min(10, len(X_test))):\n",
    "    real = int(y_test[i])\n",
    "    pred = y_pred[i]\n",
    "    confianza = confianzas[i]\n",
    "    nombre_real = class_names[real]\n",
    "    nombre_pred = class_names[pred]\n",
    "    acierto = \"Correcto\" if real == pred else \"Incorrecto\"\n",
    "    \n",
    "    print(f\"Imagen {i}: Real: {nombre_real} | Pred: {nombre_pred} | Conf: {confianza*100:5.1f}% → {acierto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ================= CONFIGURACIÓN =================\n",
    "IMG_HEIGHT = m   # Ajusta si usaste otro\n",
    "IMG_WIDTH = n\n",
    "\n",
    "# ================= FUNCIÓN CORREGIDA =================\n",
    "def mostrar_imagen_con_prediccion(idx, X_test, y_test, y_pred, confianzas, class_names):\n",
    "    # Redimensionar correctamente: (n_pixels,) → (height, width)\n",
    "    img = X_test[idx].reshape(IMG_HEIGHT, IMG_WIDTH).T\n",
    "    \n",
    "    real = class_names[int(y_test[idx])]\n",
    "    pred = class_names[y_pred[idx]]\n",
    "    confianza = confianzas[idx] * 100\n",
    "    \n",
    "    plt.figure(figsize=(4, 5))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    color = 'green' if real == pred else 'red'\n",
    "    plt.title(f'Real: {real}\\nPred: {pred} ({confianza:.1f}%)', color=color, fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ================= MOSTRAR VARIAS IMÁGENES DE PRUEBA =================\n",
    "print(\"Mostrando 5 ejemplos del conjunto de prueba (X_test):\")\n",
    "\n",
    "for i in [0, 10, 20, 30, 66]:  # Puedes cambiar los índices\n",
    "    if i < len(X_test):\n",
    "        print(f\"\\n--- Imagen {i} de X_test ---\")\n",
    "        mostrar_imagen_con_prediccion(i, X_test, y_test, y_pred, confianzas, class_names)\n",
    "    else:\n",
    "        print(f\"Índice {i} fuera de rango (X_test tiene {len(X_test)} imágenes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mostrando solo errores en X_test:\")\n",
    "errores = np.where(y_test != y_pred)[0]\n",
    "\n",
    "for i in errores[:9]:  # Primeros 5 errores\n",
    "    print(f\"\\n--- ERROR en índice {i} ---\")\n",
    "    mostrar_imagen_con_prediccion(i, X_test, y_test, y_pred, confianzas, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy en X_test: {accuracy*100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy en test: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Reporte detallado\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
