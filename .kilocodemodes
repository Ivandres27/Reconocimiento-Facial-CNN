{
  "customModes": [
    {
      "name": "ds-expert-mistral",
      "slug": "ds-expert-mistral",
      "description": "Specialized mode for Data Science and Deep Learning projects (Mistral)",
      "provider": "ollama",
      "model": "mistral",
      "apiBase": "http://localhost:11434",
      "roleDefinition": "You are an expert data scientist and machine learning engineer. Focus on writing clean, efficient Python code for ML/DL projects, following best practices for data preprocessing, model training, and evaluation. Use popular libraries like pandas, numpy, scikit-learn, tensorflow, pytorch, matplotlib, seaborn. Implement proper experiment tracking and model versioning. Write modular, reproducible code with proper documentation. Always consider data quality, proper train/validation/test splits, cross-validation strategies, hyperparameter tuning, model interpretability, and deployment considerations.",
      "groups": [],
      "templates": {
        "ml_project": {
          "description": "Complete ML project structure",
          "files": [
            "src/data/make_dataset.py",
            "src/features/build_features.py",
            "src/models/train_model.py",
            "src/models/predict_model.py",
            "notebooks/exploratory_analysis.ipynb",
            "requirements.txt"
          ]
        },
        "dl_experiment": {
          "description": "Deep learning experiment template",
          "files": [
            "models/architecture.py",
            "data/dataloader.py",
            "training/trainer.py",
            "notebooks/model_analysis.ipynb"
          ]
        }
      },
      "auto_actions": {
        "on_new_notebook": [
          "Add standard imports for data science",
          "Set up matplotlib inline",
          "Configure pandas display options"
        ],
        "on_new_py_file": [
          "Add docstring template",
          "Add standard ML imports if needed",
          "Set up logging configuration"
        ]
      },
      "suggestions": {
        "libraries": {
          "data_manipulation": ["pandas", "numpy", "polars"],
          "visualization": ["matplotlib", "seaborn", "plotly"],
          "ml_frameworks": ["scikit-learn", "xgboost", "lightgbm"],
          "dl_frameworks": ["tensorflow", "pytorch"],
          "experiment_tracking": ["mlflow", "wandb"]
        }
      },
      "shortcuts": {
        "eda": "Generate exploratory data analysis code for the dataset",
        "preprocess": "Create data preprocessing pipeline",
        "model": "Build and train a machine learning model",
        "eval": "Create model evaluation and metrics code",
        "viz": "Generate data visualization code",
        "pipeline": "Create end-to-end ML pipeline"
      },
      "context_files": [
        "*.py",
        "*.ipynb",
        "*.csv",
        "*.json",
        "*.yml",
        "*.yaml",
        "requirements.txt",
        "*.md"
      ],
      "file_patterns": {
        "include": [
          "**/*.py",
          "**/*.ipynb",
          "**/*.csv",
          "**/*.parquet",
          "**/*.pkl",
          "**/*.joblib",
          "**/*.yaml",
          "**/*.json",
          "**/requirements.txt"
        ],
        "exclude": [
          "**/__pycache__/**",
          "**/.git/**",
          "**/node_modules/**",
          "**/data/raw/**",
          "**/models/checkpoints/**"
        ]
      }
    },
    {
      "name": "ds-expert-llama2",
      "slug": "ds-expert-llama2",
      "description": "Specialized mode for Data Science and Deep Learning projects (Llama2 13B)",
      "provider": "ollama",
      "model": "llama2:13b",
      "apiBase": "http://localhost:11434",
      "roleDefinition": "You are a senior AI research engineer specializing in advanced machine learning and deep learning methods. Provide detailed explanations, reasoning, and code for implementing state-of-the-art ML/DL techniques, including CNNs, RNNs, transformers, and generative models. Optimize model architectures, hyperparameters, and training pipelines for performance and scalability. Ensure reproducibility, interpretability, and ethical AI practices. Assume the user has intermediate knowledge, so give expert-level insights with clear justifications.",
      "groups": [],
      "templates": {
        "research_project": {
          "description": "Research-oriented ML/DL project structure",
          "files": [
            "src/data/prepare_dataset.py",
            "src/models/architecture.py",
            "src/models/training_loop.py",
            "notebooks/research_experiments.ipynb",
            "README.md"
          ]
        },
        "transformer_experiment": {
          "description": "Template for NLP transformer experiments",
          "files": [
            "models/transformer.py",
            "data/text_dataset.py",
            "training/train_transformer.py",
            "notebooks/attention_visualization.ipynb"
          ]
        }
      },
      "auto_actions": {
        "on_new_notebook": [
          "Add advanced ML imports",
          "Enable autoreload for modules",
          "Set high-resolution plots"
        ],
        "on_new_py_file": [
          "Insert detailed docstring template",
          "Add logging and experiment tracking setup"
        ]
      },
      "suggestions": {
        "libraries": {
          "nlp": ["transformers", "tokenizers", "datasets"],
          "cv": ["opencv-python", "albumentations", "torchvision"],
          "optimizers": ["optuna", "ray[tune]"],
          "distributed": ["pytorch-lightning", "deepspeed"]
        }
      },
      "shortcuts": {
        "transformer": "Implement a transformer-based model for NLP",
        "cv_pipeline": "Create a computer vision training pipeline",
        "hyperopt": "Perform hyperparameter optimization using Optuna",
        "explain": "Generate interpretability plots for ML/DL models"
      },
      "context_files": [
        "*.py",
        "*.ipynb",
        "*.csv",
        "*.json",
        "*.txt",
        "*.md",
        "*.yaml",
        "*.yml"
      ],
      "file_patterns": {
        "include": [
          "**/*.py",
          "**/*.ipynb",
          "**/*.csv",
          "**/*.json",
          "**/*.yaml",
          "**/*.txt",
          "**/*.md",
          "**/requirements.txt"
        ],
        "exclude": [
          "**/__pycache__/**",
          "**/.git/**",
          "**/node_modules/**",
          "**/data/raw/**",
          "**/experiments/old/**"
        ]
      }
    }
  ]
}